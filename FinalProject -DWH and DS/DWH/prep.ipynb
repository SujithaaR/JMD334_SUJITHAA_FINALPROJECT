{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame:\n",
      "   employee_id         username    password                        email  \\\n",
      "0            1              ywu  4N5+WJQz+t  samanthaperkins@example.net   \n",
      "1            2       jennifer27  $6lGw49FVq           wevans@example.net   \n",
      "2            3         vedwards  r2Al7Ob1(&        matthew60@example.net   \n",
      "3            4  gonzalessabrina  U(5L0CfZ0*        melissa00@example.net   \n",
      "4            5        jessica89  +s3KPv#Edz          tonya60@example.org   \n",
      "\n",
      "   isAdmin            department                       team  timeSpent  gender  \n",
      "0     True       Data Management        Infrastructure Team      86049    Male  \n",
      "1     True  Software Development     Technical Support Team      56812  Female  \n",
      "2    False        Cloud Services  User Experience (UX) Team      79179    Male  \n",
      "3     True            IT Support                DevOps Team      63847    Male  \n",
      "4    False  Software Development  User Experience (UX) Team      10197    Male  \n",
      "Loading process completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the source RAW directory\n",
    "raw_dir = r\"C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\RAW\"  # Use raw string\n",
    "\n",
    "# Specify the CSV file to read\n",
    "file_name = 'employees.csv'  # Change this to the specific file you want to read\n",
    "raw_file_path = os.path.join(raw_dir, file_name)\n",
    "\n",
    "# Check if the specified file exists\n",
    "if os.path.exists(raw_file_path):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df_employee= pd.read_csv(raw_file_path)\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    print(\"Loaded DataFrame:\")\n",
    "    print(df_employee.head())  # Show the first few rows\n",
    "else:\n",
    "    print(f'The file {file_name} does not exist in the RAW folder.')\n",
    "\n",
    "print(\"Loading process completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   employee_id  300 non-null    int64 \n",
      " 1   username     300 non-null    object\n",
      " 2   password     300 non-null    object\n",
      " 3   email        300 non-null    object\n",
      " 4   isAdmin      300 non-null    bool  \n",
      " 5   department   300 non-null    object\n",
      " 6   team         300 non-null    object\n",
      " 7   timeSpent    300 non-null    int64 \n",
      " 8   gender       300 non-null    object\n",
      "dtypes: bool(1), int64(2), object(6)\n",
      "memory usage: 19.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_employee.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Convert data types where appropriate\n",
    "df_employee['department'] = df_employee['department'].astype('category')\n",
    "df_employee['team'] = df_employee['team'].astype('category')\n",
    "df_employee['gender'] = df_employee['gender'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id       int64\n",
       "username         object\n",
       "password         object\n",
       "email            object\n",
       "isAdmin            bool\n",
       "department     category\n",
       "team           category\n",
       "timeSpent         int64\n",
       "gender         category\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_employee.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   employee_id  300 non-null    int64   \n",
      " 1   username     300 non-null    object  \n",
      " 2   password     300 non-null    object  \n",
      " 3   email        300 non-null    object  \n",
      " 4   isAdmin      300 non-null    bool    \n",
      " 5   department   300 non-null    category\n",
      " 6   team         300 non-null    category\n",
      " 7   timeSpent    300 non-null    int64   \n",
      " 8   gender       300 non-null    category\n",
      "dtypes: bool(1), category(3), int64(2), object(3)\n",
      "memory usage: 13.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_employee.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING THE EMPLOYEE TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "employee_id    0\n",
      "username       0\n",
      "password       0\n",
      "email          0\n",
      "isAdmin        0\n",
      "department     0\n",
      "team           0\n",
      "timeSpent      0\n",
      "gender         0\n",
      "dtype: int64\n",
      "Cleaning process completed for Employee Table!\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   employee_id  300 non-null    object\n",
      " 1   username     300 non-null    object\n",
      " 2   email        300 non-null    object\n",
      " 3   isAdmin      300 non-null    bool  \n",
      " 4   department   300 non-null    object\n",
      " 5   team         300 non-null    object\n",
      " 6   timeSpent    300 non-null    int64 \n",
      " 7   gender       300 non-null    object\n",
      "dtypes: bool(1), int64(1), object(6)\n",
      "memory usage: 16.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df_employee[df_employee.duplicated(subset=['employee_id', 'username', 'email'])]\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicate entries found:\")\n",
    "    print(duplicates)\n",
    "\n",
    "# Convert 'employee_id' to string\n",
    "df_employee['employee_id'] = df_employee['employee_id'].astype(str)\n",
    "\n",
    "# Clean up string fields\n",
    "for col in ['username', 'email', 'department', 'team', 'gender']:\n",
    "    df_employee[col] = df_employee[col].str.strip().str.lower() if col == 'email' else df_employee[col].str.strip().str.title()\n",
    "\n",
    "# Handle missing values if applicable\n",
    "missing_values = df_employee.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Ensure boolean consistency\n",
    "if not df_employee['isAdmin'].isin([True, False]).all():\n",
    "    print(\"Inconsistent boolean values found in isAdmin.\")\n",
    "\n",
    "# Remove the password column\n",
    "df_employee = df_employee.drop(columns=['password'])\n",
    "\n",
    "# Standardize timeSpent\n",
    "df_employee['timeSpent'] = df_employee['timeSpent'].clip(lower=0)\n",
    "\n",
    "# Final validation checks\n",
    "print(\"Cleaning process completed for Employee Table!\")\n",
    "\n",
    "display(df_employee.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file saved to: C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\PREP\\cleaned_employees.csv\n",
      "Loading and cleaning process completed!\n"
     ]
    }
   ],
   "source": [
    "# Define the target PREP directory\n",
    "prep_dir = r\"C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\PREP\"  # Use raw string\n",
    "\n",
    "# Create the PREP directory if it doesn't exist\n",
    "os.makedirs(prep_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Save the cleaned DataFrame to the PREP directory\n",
    "cleaned_file_path = os.path.join(prep_dir, \"cleaned_\" + file_name)\n",
    "df_employee.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned file saved to: {cleaned_file_path}\")\n",
    "print(\"Loading and cleaning process completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING THE COURSE TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      "course_id      object\n",
      "title          object\n",
      "description    object\n",
      "topics         object\n",
      "dtype: object\n",
      "\n",
      "Loaded DataFrame:\n",
      "  course_id                                 title  \\\n",
      "0         1   Proactive demand-driven methodology   \n",
      "1         2      Down-sized intermediate strategy   \n",
      "2         3    Object-based zero-defect emulation   \n",
      "3         4   Customizable background methodology   \n",
      "4         5  Cross-platform grid-enabled alliance   \n",
      "\n",
      "                                         description  \\\n",
      "0  Wife training run yourself they performance ru...   \n",
      "1  Conference quality low. Weight my wife nationa...   \n",
      "2  Good what put method benefit. Option see speci...   \n",
      "3  Collection evening central both opportunity im...   \n",
      "4  Claim not manager watch ago interesting inside...   \n",
      "\n",
      "                                              topics  \n",
      "0  [{'title': 'fly', 'subtopics': [{'title': 'Sta...  \n",
      "1  [{'title': 'investment', 'subtopics': [{'title...  \n",
      "2  [{'title': 'will', 'subtopics': [{'title': 'Fo...  \n",
      "3  [{'title': 'eye', 'subtopics': [{'title': 'Erg...  \n",
      "4  [{'title': 'spring', 'subtopics': [{'title': '...  \n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   course_id    20 non-null     object\n",
      " 1   title        20 non-null     object\n",
      " 2   description  20 non-null     object\n",
      " 3   topics       20 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 772.0+ bytes\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "course_id      0\n",
      "title          0\n",
      "description    0\n",
      "topics         0\n",
      "dtype: int64\n",
      "\n",
      "Categorical Columns:\n",
      "Index(['course_id', 'title', 'description', 'topics'], dtype='object')\n",
      "\n",
      "Numerical Columns:\n",
      "Index([], dtype='object')\n",
      "\n",
      "Data Types After Conversion:\n",
      "course_id      object\n",
      "title          object\n",
      "description    object\n",
      "topics         object\n",
      "dtype: object\n",
      "\n",
      "Cleaned DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   course_id    20 non-null     object\n",
      " 1   title        20 non-null     object\n",
      " 2   description  20 non-null     object\n",
      " 3   topics       20 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 772.0+ bytes\n",
      "None\n",
      "cleaning process done\n",
      "Cleaned file saved to: C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\PREP\\cleaned_courses.csv\n",
      "Loading and cleaning process completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the source RAW directory\n",
    "raw_dir = r\"C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\RAW\"  # Use raw string\n",
    "\n",
    "# Specify the CSV file to read\n",
    "file_name = 'courses.csv'  # Change this to the specific file you want to read\n",
    "raw_file_path = os.path.join(raw_dir, file_name)\n",
    "\n",
    "# Check if the specified file exists\n",
    "if os.path.exists(raw_file_path):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df_courses = pd.read_csv(raw_file_path)\n",
    "    \n",
    "    # Convert 'course_id' to string\n",
    "    df_courses['course_id'] = df_courses['course_id'].astype(str)\n",
    "    \n",
    "    # Display data types\n",
    "    print(\"Data Types:\")\n",
    "    print(df_courses.dtypes)  # Corrected here\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(\"\\nLoaded DataFrame:\")\n",
    "    print(df_courses.head())  # Show the first few rows\n",
    "    \n",
    "    # Step 1: Explore the Data\n",
    "    print(\"\\nData Info:\")\n",
    "    print(df_courses.info())\n",
    "    \n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df_courses.isnull().sum())\n",
    "\n",
    "    # Step 2: Handle Missing Values\n",
    "    # Example: Fill missing values with a placeholder for categorical columns\n",
    "    categorical_cols = df_courses.select_dtypes(include=['object']).columns\n",
    "    print(\"\\nCategorical Columns:\")\n",
    "    print(categorical_cols)\n",
    "    df_courses[categorical_cols] = df_courses[categorical_cols].fillna('Unknown')\n",
    "\n",
    "    # Example: Fill missing values with the mean for numerical columns\n",
    "    numerical_cols = df_courses.select_dtypes(include=['float64', 'int64']).columns\n",
    "    print(\"\\nNumerical Columns:\")\n",
    "    print(numerical_cols)\n",
    "    df_courses[numerical_cols] = df_courses[numerical_cols].fillna(df_courses[numerical_cols].mean())\n",
    "\n",
    "    # Step 3: Convert Data Types\n",
    "    # Example: Convert course_type column to category type\n",
    "    if 'course_type' in df_courses.columns:  # Replace with actual column name if necessary\n",
    "        df_courses['course_type'] = df_courses['course_type'].astype('category')\n",
    "\n",
    "    # Display data types after conversions\n",
    "    print(\"\\nData Types After Conversion:\")\n",
    "    print(df_courses.dtypes)  # Corrected here\n",
    "    \n",
    "    # Step 4: Final DataFrame Review\n",
    "    print(\"\\nCleaned DataFrame:\")\n",
    "    print(df_courses.info())\n",
    "    \n",
    "else:\n",
    "    print(f'The file {file_name} does not exist in the RAW folder.')\n",
    "\n",
    "print(\"cleaning process done\")\n",
    "\n",
    "\n",
    "# Define the target PREP directory\n",
    "prep_dir = r\"C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\PREP\"  # Use raw string\n",
    "\n",
    "# Create the PREP directory if it doesn't exist\n",
    "os.makedirs(prep_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Save the cleaned DataFrame to the PREP directory\n",
    "cleaned_file_path = os.path.join(prep_dir, \"cleaned_\" + file_name)\n",
    "df_courses.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned file saved to: {cleaned_file_path}\")\n",
    "print(\"Loading and cleaning process completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING THE ENROLLMENT TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before cleaning:\n",
      "enrollmentId      0\n",
      "userId            0\n",
      "courseId          0\n",
      "enrolledAt        0\n",
      "progress          0\n",
      "completed         0\n",
      "totalCount        0\n",
      "completedCount    0\n",
      "isQuizTaken       0\n",
      "isParticipated    0\n",
      "isFeedback        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "enrollmentId      object\n",
       "userId            object\n",
       "courseId          object\n",
       "enrolledAt        object\n",
       "progress           int64\n",
       "completed           bool\n",
       "totalCount         int64\n",
       "completedCount     int64\n",
       "isQuizTaken         bool\n",
       "isParticipated      bool\n",
       "isFeedback          bool\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning:\n",
      "     enrollmentId userId courseId  enrolledAt  progress  completed  \\\n",
      "0        rQS0kpxX    158       16  2024-10-07        71      False   \n",
      "1        3AStlgcU    130       13  2024-10-07        76      False   \n",
      "2        E2UsVdTq    172       18  2024-10-07        14      False   \n",
      "3        fh9DWDHa    271       13  2024-10-07        60      False   \n",
      "4        tmdGzFZb    246       20  2024-10-07        30      False   \n",
      "...           ...    ...      ...         ...       ...        ...   \n",
      "4995     BhMALCFI    226       18  2024-10-07        35      False   \n",
      "4996     bSPIrNNP     22        1  2024-10-07        45      False   \n",
      "4997     L9WIvrWd    110        8  2024-10-07        74      False   \n",
      "4998     n12qJBay    157        3  2024-10-07        94      False   \n",
      "4999     ZeyNul6l     69       12  2024-10-07        62      False   \n",
      "\n",
      "      totalCount  completedCount  isQuizTaken  isParticipated  isFeedback  \n",
      "0              9               8        False            True        True  \n",
      "1              9               7         True            True       False  \n",
      "2             10               8         True            True       False  \n",
      "3             11              10        False            True        True  \n",
      "4             17               4         True            True       False  \n",
      "...          ...             ...          ...             ...         ...  \n",
      "4995          13              10         True            True        True  \n",
      "4996          15              11         True           False       False  \n",
      "4997           5               4        False            True        True  \n",
      "4998           6               2         True            True        True  \n",
      "4999          11               6        False            True       False  \n",
      "\n",
      "[5000 rows x 11 columns]\n",
      "Cleaned file saved to: C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\PREP\\cleaned_enrollment.csv\n",
      "Loading and cleaning process completed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the source RAW directory\n",
    "raw_dir = r\"C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\RAW\"  # Use raw string\n",
    "\n",
    "# Specify the CSV file to read\n",
    "file_name = 'enrollment.csv'  # Change this to the specific file you want to read \n",
    "raw_file_path = os.path.join(raw_dir, file_name)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_enrollment = pd.read_csv(raw_file_path)\n",
    "\n",
    "# Convert 'enrolledAt' to datetime\n",
    "df_enrollment['enrolledAt'] = pd.to_datetime(df_enrollment['enrolledAt'], errors='coerce')\n",
    "\n",
    "\n",
    "# Extract only the date portion and convert to string\n",
    "df_enrollment['enrolledAt'] = df_enrollment['enrolledAt'].dt.date\n",
    "\n",
    "\n",
    "# Check for and handle missing values\n",
    "print(\"Missing values before cleaning:\")\n",
    "print(df_enrollment.isnull().sum())\n",
    "\n",
    "# Drop rows with missing 'enrollmentId', 'userId', or 'courseId'\n",
    "df_enrollment = df_enrollment.dropna(subset=['enrollmentId', 'userId', 'courseId'])\n",
    "\n",
    "# Remove duplicates based on 'enrollmentId'\n",
    "df_enrollment = df_enrollment.drop_duplicates(subset=['enrollmentId'])\n",
    "\n",
    "# Validate logical relationships\n",
    "df_enrollment = df_enrollment[(df_enrollment['completedCount'] <= df_enrollment['totalCount']) & (df_enrollment['completedCount'] >= 0)]\n",
    "\n",
    "# Check for valid progress values (0-100)\n",
    "df_enrollment = df_enrollment[(df_enrollment['progress'] >= 0) & (df_enrollment['progress'] <= 100)]\n",
    "\n",
    "# Ensure correct data types\n",
    "df_enrollment['userId'] = df_enrollment['userId'].astype(str)\n",
    "df_enrollment['courseId'] = df_enrollment['courseId'].astype(str)\n",
    "df_enrollment['enrollmentId'] = df_enrollment['enrollmentId'].astype(str)\n",
    "df_enrollment['completed'] = df_enrollment['completed'].astype(bool)\n",
    "df_enrollment['isQuizTaken'] = df_enrollment['isQuizTaken'].astype(bool)\n",
    "df_enrollment['isParticipated'] = df_enrollment['isParticipated'].astype(bool)\n",
    "df_enrollment['isFeedback'] = df_enrollment['isFeedback'].astype(bool)\n",
    "\n",
    "\n",
    "display(df_enrollment.dtypes)\n",
    "# Print the cleaned data\n",
    "print(\"Data after cleaning:\")\n",
    "print(df_enrollment)\n",
    "\n",
    "# Define the target PREP directory\n",
    "prep_dir = r\"C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\PREP\"  # Use raw string\n",
    "\n",
    "# Create the PREP directory if it doesn't exist\n",
    "os.makedirs(prep_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Save the cleaned DataFrame to the PREP directory\n",
    "cleaned_file_path = os.path.join(prep_dir, \"cleaned_\" + file_name)\n",
    "df_enrollment.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned file saved to: {cleaned_file_path}\")\n",
    "print(\"Loading and cleaning process completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING THE QUIZ TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data types:\n",
      "quizId           object\n",
      "userId            int64\n",
      "courseId          int64\n",
      "enrollmentId     object\n",
      "totalScore        int64\n",
      "obtainedScore     int64\n",
      "date             object\n",
      "dtype: object\n",
      "\n",
      "Data types after conversion:\n",
      "quizId           object\n",
      "userId           object\n",
      "courseId         object\n",
      "enrollmentId     object\n",
      "totalScore        int64\n",
      "obtainedScore     int64\n",
      "date             object\n",
      "dtype: object\n",
      "Missing values in df_quiz before cleaning:\n",
      "quizId           0\n",
      "userId           0\n",
      "courseId         0\n",
      "enrollmentId     0\n",
      "totalScore       0\n",
      "obtainedScore    0\n",
      "date             0\n",
      "dtype: int64\n",
      "Data after cleaning df_quiz:\n",
      "        quizId userId courseId enrollmentId  totalScore  obtainedScore  \\\n",
      "0     geZDcEVf    130       13     3AStlgcU         100             72   \n",
      "1     uKsA0JGS    172       18     E2UsVdTq         100             15   \n",
      "2     6UmT7Imw    246       20     tmdGzFZb         100             26   \n",
      "3     K0oGn9b4    135       12     Gs0zOMyg         100             16   \n",
      "4     GwaNiBIx    126       17     N8sqpKOE         100             87   \n",
      "...        ...    ...      ...          ...         ...            ...   \n",
      "2488  lv0zYCdB     60       12     nVhDUT9w         100              5   \n",
      "2489  YGOyT7Cf    224       10     MmX2sRj7         100             94   \n",
      "2490  Mm2KbWI3    226       18     BhMALCFI         100             31   \n",
      "2491  p5yovIoX     22        1     bSPIrNNP         100             44   \n",
      "2492  sCreqADW    157        3     n12qJBay         100             94   \n",
      "\n",
      "            date  \n",
      "0     2024-10-07  \n",
      "1     2024-10-07  \n",
      "2     2024-10-07  \n",
      "3     2024-10-07  \n",
      "4     2024-10-07  \n",
      "...          ...  \n",
      "2488  2024-10-07  \n",
      "2489  2024-10-07  \n",
      "2490  2024-10-07  \n",
      "2491  2024-10-07  \n",
      "2492  2024-10-07  \n",
      "\n",
      "[2493 rows x 7 columns]\n",
      "Cleaned file saved to: C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\PREP\\cleaned_quiz_results.csv\n",
      "Loading and cleaning process completed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the source RAW directory\n",
    "raw_dir = r\"C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\RAW\"  # Use raw string\n",
    "\n",
    "# Specify the CSV file to read\n",
    "file_name = 'quiz_results.csv'  # Change this to the specific file you want to read \n",
    "raw_file_path = os.path.join(raw_dir, file_name)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_quiz = pd.read_csv(raw_file_path)\n",
    "\n",
    "df_quiz.dtypes\n",
    "# Display initial data types\n",
    "print(\"Initial data types:\")\n",
    "print(df_quiz.dtypes)\n",
    "\n",
    "\n",
    "# Convert 'date' to datetime\n",
    "df_quiz['date'] = pd.to_datetime(df_quiz['date'], errors='coerce').dt.date\n",
    "\n",
    "# Ensure correct data types\n",
    "df_quiz['quizId'] = df_quiz['quizId'].astype(str)\n",
    "df_quiz['userId'] = df_quiz['userId'].astype(str)\n",
    "df_quiz['courseId'] = df_quiz['courseId'].astype(str)\n",
    "df_quiz['enrollmentId'] = df_quiz['enrollmentId'].astype(str)\n",
    "\n",
    "print()\n",
    "# Check the data types to confirm conversion\n",
    "print(\"Data types after conversion:\")\n",
    "print(df_quiz.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in df_quiz before cleaning:\")\n",
    "print(df_quiz.isnull().sum())\n",
    "\n",
    "# Drop rows with missing crucial information\n",
    "df_quiz = df_quiz.dropna(subset=['quizId', 'userId', 'courseId', 'enrollmentId', 'obtainedScore'])\n",
    "\n",
    "# Ensure obtainedScore is non-negative\n",
    "df_quiz = df_quiz[df_quiz['obtainedScore'] >= 0]\n",
    "\n",
    "# Check for valid totalScore (should be 100)\n",
    "df_quiz = df_quiz[df_quiz['totalScore'] == 100]\n",
    "\n",
    "# Remove duplicates based on 'quizId'\n",
    "df_quiz = df_quiz.drop_duplicates(subset=['quizId'])\n",
    "\n",
    "\n",
    "df_quiz.dtypes\n",
    "\n",
    "# Print cleaned df_quiz\n",
    "print(\"Data after cleaning df_quiz:\")\n",
    "print(df_quiz)\n",
    "\n",
    "\n",
    "# Define the target PREP directory\n",
    "prep_dir = r\"C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\PREP\"  # Use raw string\n",
    "\n",
    "# Create the PREP directory if it doesn't exist\n",
    "os.makedirs(prep_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Save the cleaned DataFrame to the PREP directory\n",
    "cleaned_file_path = os.path.join(prep_dir, \"cleaned_\" + file_name)\n",
    "df_quiz.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned file saved to: {cleaned_file_path}\")\n",
    "print(\"Loading and cleaning process completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING THE FEEDBACK TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data types:\n",
      "feedbackId                 object\n",
      "courseId                    int64\n",
      "userId                      int64\n",
      "enrollmentId               object\n",
      "overallSatisfaction         int64\n",
      "contentQuality              int64\n",
      "instructorEffectiveness     int64\n",
      "comments                   object\n",
      "createdAt                  object\n",
      "dtype: object\n",
      "\n",
      "Data types after conversion:\n",
      "feedbackId                 object\n",
      "courseId                   object\n",
      "userId                     object\n",
      "enrollmentId               object\n",
      "overallSatisfaction         int64\n",
      "contentQuality              int64\n",
      "instructorEffectiveness     int64\n",
      "comments                   object\n",
      "createdAt                  object\n",
      "dtype: object\n",
      "Missing values in df_feedback before cleaning:\n",
      "feedbackId                 0\n",
      "courseId                   0\n",
      "userId                     0\n",
      "enrollmentId               0\n",
      "overallSatisfaction        0\n",
      "contentQuality             0\n",
      "instructorEffectiveness    0\n",
      "comments                   0\n",
      "createdAt                  0\n",
      "dtype: int64\n",
      "Data after cleaning df_feedback:\n",
      "     feedbackId courseId userId enrollmentId  overallSatisfaction  \\\n",
      "0      TaQVarow       16    158     rQS0kpxX                    2   \n",
      "1      OvMsaQPX       13    271     fh9DWDHa                    3   \n",
      "2      dAQdeiVv       13    297     ZelKutIJ                    3   \n",
      "3      bERI005p        7    143     Rh4AZ9uM                    4   \n",
      "4      omQJThTb       20    107     RmyjsCVX                    1   \n",
      "...         ...      ...    ...          ...                  ...   \n",
      "2483   3MkabLS1       12    100     YBGKfR0J                    1   \n",
      "2484   HcdIHY7H       10    224     MmX2sRj7                    3   \n",
      "2485   pyhPOxse       18    226     BhMALCFI                    3   \n",
      "2486   qwMTwYWn        8    110     L9WIvrWd                    5   \n",
      "2487   PhSeD49k        3    157     n12qJBay                    2   \n",
      "\n",
      "      contentQuality  instructorEffectiveness           comments   createdAt  \n",
      "0                  3                        1  Very informative.  2024-10-07  \n",
      "1                  1                        5      Great course!  2024-10-07  \n",
      "2                  4                        5   Could be better.  2024-10-07  \n",
      "3                  1                        5   Could be better.  2024-10-07  \n",
      "4                  1                        2      Great course!  2024-10-07  \n",
      "...              ...                      ...                ...         ...  \n",
      "2483               4                        3  Very informative.  2024-10-07  \n",
      "2484               5                        2      Great course!  2024-10-07  \n",
      "2485               4                        1  Very informative.  2024-10-07  \n",
      "2486               2                        4   Could be better.  2024-10-07  \n",
      "2487               5                        2   Could be better.  2024-10-07  \n",
      "\n",
      "[2488 rows x 9 columns]\n",
      "Cleaned file saved to: C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\PREP\\cleaned_feedback.csv\n",
      "Loading and cleaning process for feedback completed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the source RAW directory\n",
    "raw_dir = r\"C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\RAW\"  # Use raw string\n",
    "\n",
    "# Specify the CSV file to read\n",
    "file_name = 'feedback.csv'  # Change this to the specific file you want to read \n",
    "raw_file_path = os.path.join(raw_dir, file_name)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_feedback = pd.read_csv(raw_file_path)\n",
    "\n",
    "# Display initial data types\n",
    "print(\"Initial data types:\")\n",
    "print(df_feedback.dtypes)\n",
    "\n",
    "# Convert 'createdAt' to datetime and extract only the date portion\n",
    "df_feedback['createdAt'] = pd.to_datetime(df_feedback['createdAt'], errors='coerce').dt.date\n",
    "\n",
    "# Ensure correct data types\n",
    "df_feedback['feedbackId'] = df_feedback['feedbackId'].astype(str)\n",
    "df_feedback['courseId'] = df_feedback['courseId'].astype(str)\n",
    "df_feedback['userId'] = df_feedback['userId'].astype(str)\n",
    "df_feedback['enrollmentId'] = df_feedback['enrollmentId'].astype(str)\n",
    "\n",
    "print()\n",
    "# Check the data types to confirm conversion\n",
    "print(\"Data types after conversion:\")\n",
    "print(df_feedback.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in df_feedback before cleaning:\")\n",
    "print(df_feedback.isnull().sum())\n",
    "\n",
    "# Drop rows with missing crucial information\n",
    "df_feedback = df_feedback.dropna(subset=['feedbackId', 'userId', 'courseId', 'enrollmentId', \n",
    "                                          'overallSatisfaction', 'contentQuality', 'instructorEffectiveness'])\n",
    "\n",
    "# Ensure scores are within valid ranges (assuming valid range is 1-5)\n",
    "df_feedback = df_feedback[(df_feedback['overallSatisfaction'].between(1, 5)) &\n",
    "                          (df_feedback['contentQuality'].between(1, 5)) &\n",
    "                          (df_feedback['instructorEffectiveness'].between(1, 5))]\n",
    "\n",
    "# Remove duplicates based on 'feedbackId'\n",
    "df_feedback = df_feedback.drop_duplicates(subset=['feedbackId'])\n",
    "\n",
    "# Print cleaned df_feedback\n",
    "print(\"Data after cleaning df_feedback:\")\n",
    "print(df_feedback)\n",
    "\n",
    "# Define the target PREP directory\n",
    "prep_dir = r\"C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\PREP\"  # Use raw string\n",
    "\n",
    "# Create the PREP directory if it doesn't exist\n",
    "os.makedirs(prep_dir, exist_ok=True)\n",
    "\n",
    "# Save the cleaned DataFrame to the PREP directory\n",
    "cleaned_file_path = os.path.join(prep_dir, \"cleaned_\" + file_name)\n",
    "df_feedback.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned file saved to: {cleaned_file_path}\")\n",
    "print(\"Loading and cleaning process for feedback completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING THE COMMENT TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data types:\n",
      "commentId       object\n",
      "userId           int64\n",
      "enrollmentId    object\n",
      "courseId         int64\n",
      "content         object\n",
      "createdAt       object\n",
      "dtype: object\n",
      "\n",
      "Data types after conversion:\n",
      "commentId       object\n",
      "userId          object\n",
      "enrollmentId    object\n",
      "courseId        object\n",
      "content         object\n",
      "createdAt       object\n",
      "dtype: object\n",
      "Missing values in df_comments before cleaning:\n",
      "commentId       0\n",
      "userId          0\n",
      "enrollmentId    0\n",
      "courseId        0\n",
      "content         0\n",
      "createdAt       0\n",
      "dtype: int64\n",
      "Data after cleaning df_comments:\n",
      "     commentId userId enrollmentId courseId               content   createdAt\n",
      "0     iUESyDUX    158     rQS0kpxX       16     I didn't like it.  2024-10-07\n",
      "1     WBuCjKpE    130     3AStlgcU       13          It was okay.  2024-10-07\n",
      "2     b6BtFazt    172     E2UsVdTq       18     I didn't like it.  2024-10-07\n",
      "3     t85h8iFH    271     fh9DWDHa       13          It was okay.  2024-10-07\n",
      "4     hBoMEwLn    246     tmdGzFZb       20          It was okay.  2024-10-07\n",
      "...        ...    ...          ...      ...                   ...         ...\n",
      "2430  NjzA9M4x    119     DBIxXjz8       10  I loved this course!  2024-10-07\n",
      "2431  2PNxUMzq    226     BhMALCFI       18  I loved this course!  2024-10-07\n",
      "2432  kmZp66yq    110     L9WIvrWd        8     I didn't like it.  2024-10-07\n",
      "2433  UIDyldBe    157     n12qJBay        3  I loved this course!  2024-10-07\n",
      "2434  YFR5bgMh     69     ZeyNul6l       12  I loved this course!  2024-10-07\n",
      "\n",
      "[2435 rows x 6 columns]\n",
      "Cleaned file saved to: C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\PREP\\cleaned_comments.csv\n",
      "Loading and cleaning process for comments completed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the source RAW directory\n",
    "raw_dir = r\"C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\RAW\"  # Use raw string\n",
    "\n",
    "# Specify the CSV file to read\n",
    "file_name = 'comments.csv'  # Change this to the specific file you want to read \n",
    "raw_file_path = os.path.join(raw_dir, file_name)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_comments = pd.read_csv(raw_file_path)\n",
    "\n",
    "# Display initial data types\n",
    "print(\"Initial data types:\")\n",
    "print(df_comments.dtypes)\n",
    "\n",
    "# Convert 'createdAt' to datetime and extract only the date portion\n",
    "df_comments['createdAt'] = pd.to_datetime(df_comments['createdAt'], errors='coerce').dt.date\n",
    "\n",
    "# Ensure correct data types\n",
    "df_comments['commentId'] = df_comments['commentId'].astype(str)\n",
    "df_comments['userId'] = df_comments['userId'].astype(str)\n",
    "df_comments['enrollmentId'] = df_comments['enrollmentId'].astype(str)\n",
    "df_comments['courseId'] = df_comments['courseId'].astype(str)\n",
    "\n",
    "print()\n",
    "# Check the data types to confirm conversion\n",
    "print(\"Data types after conversion:\")\n",
    "print(df_comments.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in df_comments before cleaning:\")\n",
    "print(df_comments.isnull().sum())\n",
    "\n",
    "# Drop rows with missing crucial information\n",
    "df_comments = df_comments.dropna(subset=['commentId', 'userId', 'enrollmentId', 'courseId', 'content'])\n",
    "\n",
    "# Remove duplicates based on 'commentId'\n",
    "df_comments = df_comments.drop_duplicates(subset=['commentId'])\n",
    "\n",
    "# Print cleaned df_comments\n",
    "print(\"Data after cleaning df_comments:\")\n",
    "print(df_comments)\n",
    "\n",
    "# Define the target PREP directory\n",
    "prep_dir = r\"C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\PREP\"  # Use raw string\n",
    "\n",
    "# Create the PREP directory if it doesn't exist\n",
    "os.makedirs(prep_dir, exist_ok=True)\n",
    "\n",
    "# Save the cleaned DataFrame to the PREP directory\n",
    "cleaned_file_path = os.path.join(prep_dir, \"cleaned_\" + file_name)\n",
    "df_comments.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned file saved to: {cleaned_file_path}\")\n",
    "print(\"Loading and cleaning process for comments completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING THE ENGAGEMENT TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data types:\n",
      "userId           int64\n",
      "enrollmentId    object\n",
      "courseId         int64\n",
      "engagement       int64\n",
      "dtype: object\n",
      "\n",
      "Data types after conversion:\n",
      "userId          object\n",
      "enrollmentId    object\n",
      "courseId        object\n",
      "engagement       int32\n",
      "dtype: object\n",
      "Missing values in df_engagement before cleaning:\n",
      "userId          0\n",
      "enrollmentId    0\n",
      "courseId        0\n",
      "engagement      0\n",
      "dtype: int64\n",
      "Data after cleaning df_engagement:\n",
      "     userId enrollmentId courseId  engagement\n",
      "0       158     rQS0kpxX       16           0\n",
      "1       130     3AStlgcU       13           0\n",
      "2       172     E2UsVdTq       18           0\n",
      "3       271     fh9DWDHa       13           1\n",
      "4       246     tmdGzFZb       20           1\n",
      "...     ...          ...      ...         ...\n",
      "4995    226     BhMALCFI       18           1\n",
      "4996     22     bSPIrNNP        1           1\n",
      "4997    110     L9WIvrWd        8           1\n",
      "4998    157     n12qJBay        3           1\n",
      "4999     69     ZeyNul6l       12           1\n",
      "\n",
      "[5000 rows x 4 columns]\n",
      "Cleaned file saved to: C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\PREP\\cleaned_modified_engagement.csv\n",
      "Loading and cleaning process for engagement completed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the source RAW directory\n",
    "raw_dir = r\"C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\RAW\"  # Adjust as necessary\n",
    "\n",
    "# Specify the CSV file for the engagement data\n",
    "file_name = 'modified_engagement.csv'  # Change this to your engagement file\n",
    "raw_file_path = os.path.join(raw_dir, file_name)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_engagement = pd.read_csv(raw_file_path)\n",
    "\n",
    "# Display initial data types\n",
    "print(\"Initial data types:\")\n",
    "print(df_engagement.dtypes)\n",
    "\n",
    "# Ensure correct data types\n",
    "df_engagement['userId'] = df_engagement['userId'].astype(str)\n",
    "df_engagement['enrollmentId'] = df_engagement['enrollmentId'].astype(str)\n",
    "df_engagement['courseId'] = df_engagement['courseId'].astype(str)\n",
    "df_engagement['engagement'] = df_engagement['engagement'].astype(int)\n",
    "\n",
    "print()\n",
    "# Check the data types to confirm conversion\n",
    "print(\"Data types after conversion:\")\n",
    "print(df_engagement.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in df_engagement before cleaning:\")\n",
    "print(df_engagement.isnull().sum())\n",
    "\n",
    "# Drop rows with missing crucial information\n",
    "df_engagement = df_engagement.dropna(subset=['userId', 'enrollmentId', 'courseId', 'engagement'])\n",
    "\n",
    "# Remove duplicates based on 'enrollmentId' and 'userId' (or any other relevant subset)\n",
    "df_engagement = df_engagement.drop_duplicates(subset=['enrollmentId', 'userId'])\n",
    "\n",
    "# Print cleaned df_engagement\n",
    "print(\"Data after cleaning df_engagement:\")\n",
    "print(df_engagement)\n",
    "\n",
    "# Define the target PREP directory\n",
    "prep_dir = r\"C:\\Users\\SujithaaR\\Documents\\FinalProject -DWH and DS\\DWH\\PREP\"  # Adjust as necessary\n",
    "\n",
    "# Create the PREP directory if it doesn't exist\n",
    "os.makedirs(prep_dir, exist_ok=True)\n",
    "\n",
    "# Save the cleaned DataFrame to the PREP directory\n",
    "cleaned_file_path = os.path.join(prep_dir, \"cleaned_\" + file_name)\n",
    "df_engagement.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned file saved to: {cleaned_file_path}\")\n",
    "print(\"Loading and cleaning process for engagement completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
